model:
  version: upscaler_v2 # Model version options: upscaler_v1, upscaler_v2

dataset:
  version: seagull_dataset # Dataset version options: seagull_dataset

learning:
  epoch_amount: 500
  batch_size: 16
  loss: mse # Loss options: mse
  lr: 0.005
  scheduler: None # Scheduler options: TODO
  optimizer_type: Adam # Optimizer type options: Adam, SGD
  log_every_n_steps: 5
  # notes: Baseline experiment # Notes for current experiment

server:
  accelerator:
    type: gpu # Accelerator options: gpu, cpu
    devices: 1